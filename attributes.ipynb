{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from pylab import *\n",
    "from PIL import Image\n",
    "from statistics import mean \n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "e=[]\n",
    "h=[]\n",
    "label=[]\n",
    "i=0\n",
    "for img in glob.glob('dataset1/*/*'):\n",
    "    e.append([])\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    im = cv2.imread(img)\n",
    "    h = hog.compute(im)\n",
    "    \n",
    "    \n",
    "    pca = PCA(n_components=1)\n",
    "    principalComponents = pca.fit_transform(h)\n",
    "    principalDf = pd.DataFrame(data = principalComponents)\n",
    "    h=principalDf.values.T.tolist()\n",
    "    \n",
    "    e[i].append(h)\n",
    "    i=i+1\n",
    "e=np.asarray(e)\n",
    "size = len(e)\n",
    "TwoDim_dataset = e.reshape(size,-2)\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pc = pca.fit_transform(TwoDim_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42168674698795183\n",
      "Precision 0.26111382510991693\n",
      "recall 0.38192799070847855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import glob\n",
    "p=[]\n",
    "r=[]\n",
    "label=[]\n",
    "for im in glob.glob('dataset1/*/*'):\n",
    "   l=(im.split('.')[0].split('\\\\')[1])\n",
    "   label.append(l)\n",
    "X_train, X_test, y_train, y_test = train_test_split(pc, label, test_size=0.2,random_state=109)\n",
    "    \n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "p.append(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "r.append(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Precision\",precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"recall\",recall_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "from skimage import data, exposure\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from statistics import mean \n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "a=[]\n",
    "features=[]\n",
    "i=0\n",
    "for img in glob.glob('dataset1/*/*'):\n",
    "        im = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "        features = cv2.HuMoments(cv2.moments(im)).flatten()\n",
    "     \n",
    "       # features[i] = -1* copysign(1.0, features[i]) * log10(abs(features[i]))\n",
    "        a.append(features);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pc1 = pca.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os \n",
    "import glob \n",
    "gradient = []\n",
    "feature =[]\n",
    "\n",
    "for im in glob.glob('dataset1/*/*'):\n",
    "   # im = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "   # im = cv2.UMat(img)\n",
    "    img = (cv2.imread(im, cv2.IMREAD_COLOR))\n",
    "    #imgUMat = cv2.UMat(img)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    feature = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "    gradient.append(feature)\n",
    "   \n",
    "myarray = np.asarray(gradient)\n",
    "dataset_size = len(myarray)\n",
    "TwoDim_dataset = myarray.reshape(dataset_size,-2)\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pc2 = pca.fit_transform(TwoDim_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.feature import blob_log\n",
    "from skimage import data, exposure\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "e=[]\n",
    "i=0\n",
    "for img in glob.glob('dataset1/*/*'):\n",
    "    e.append([])\n",
    "    image = imread(img)\n",
    "    image_gray = rgb2gray(image)\n",
    "    blobs_log = blob_log(image_gray, max_sigma=30, num_sigma=10, threshold=.1)\n",
    "    blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2)\n",
    "    e[i].append(blobs_log)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "m=0\n",
    "arr=[]\n",
    "\n",
    "l=range(len(e))\n",
    "for j in l:\n",
    "    k=[]\n",
    "    for i in e[j][0]:\n",
    "        k.append(i)\n",
    "    m=sum(k)/len(k)\n",
    "    m=m.flat\n",
    "    arr.append(list(m))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os \n",
    "import glob\n",
    "tophat = []\n",
    "\n",
    "for img in glob.glob('dataset1/*/*'):\n",
    "    n= cv2.imread(img)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    #feature = cv2.morphologyEx(n, cv2.MORPH_GRADIENT, kernel)\n",
    "    feature = cv2.morphologyEx(n, cv2.MORPH_TOPHAT, kernel)\n",
    "    tophat.append(feature)\n",
    "    import numpy as np\n",
    "myarray=np.asarray(tophat)\n",
    "dataset_size = len(myarray)\n",
    "TwoDim_dataset2 = myarray.reshape(dataset_size,-2)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pc3 = pca.fit_transform(TwoDim_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os \n",
    "import glob\n",
    "blackhat = []\n",
    "\n",
    "for img in glob.glob('dataset1/*/*'):\n",
    "    n= cv2.imread(img)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    #feature = cv2.morphologyEx(n, cv2.MORPH_GRADIENT, kernel)\n",
    "    #feature = cv2.morphologyEx(n, cv2.MORPH_TOPHAT, kernel)\n",
    "    feature = cv2.morphologyEx(n, cv2.MORPH_BLACKHAT, kernel)\n",
    "    blackhat.append(feature)\n",
    "    import numpy as np\n",
    "myarray=np.asarray(blackhat)\n",
    "dataset_size = len(myarray)\n",
    "TwoDim_dataset2 = myarray.reshape(dataset_size,-2)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pc4 = pca.fit_transform(TwoDim_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os \n",
    "import glob\n",
    "erosion = []\n",
    "\n",
    "for img in glob.glob('dataset1/*/*'):\n",
    "    n= cv2.imread(img)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    feature = cv2.morphologyEx(n, cv2.MORPH_GRADIENT, kernel)\n",
    "    \n",
    "    erosion.append(feature)\n",
    "    import numpy as np\n",
    "myarray=np.asarray(erosion)\n",
    "dataset_size = len(myarray)\n",
    "TwoDim_dataset1 = myarray.reshape(dataset_size,-2)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pc5 = pca.fit_transform(TwoDim_dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os \n",
    "import glob\n",
    "dilation = []\n",
    "\n",
    "for img in glob.glob('dataset1/*/*'):\n",
    "    n= cv2.imread(img)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    #feature = cv2.morphologyEx(n, cv2.MORPH_GRADIENT, kernel)\n",
    "    #feature = cv2.morphologyEx(n, cv2.MORPH_TOPHAT, kernel)\n",
    "    #feature = cv2.morphologyEx(n, cv2.MORPH_BLACKHAT, kernel)\n",
    "    feature= cv2.dilate(n,kernel,iterations = 1)\n",
    "    dilation.append(feature)\n",
    "    import numpy as np\n",
    "myarray=np.asarray( dilation)\n",
    "dataset_size = len(myarray)\n",
    "TwoDim_dataset2 = myarray.reshape(dataset_size,-2)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pc6 = pca.fit_transform(TwoDim_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "set=np.column_stack((pc,pc1,pc2,arr,pc3,pc4,pc5,pc6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48493975903614456\n",
      "Precision 0.46859687591916643\n",
      "recall 0.45896948667107285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import glob\n",
    "p=[]\n",
    "r=[]\n",
    "label=[]\n",
    "for im in glob.glob('dataset1/*/*'):\n",
    "   l=(im.split('.')[0].split('\\\\')[1])\n",
    "   label.append(l)\n",
    "X_train, X_test, y_train, y_test = train_test_split(set, label, test_size=0.4,random_state=4)\n",
    "    \n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "p.append(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "r.append(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Precision\",precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"recall\",recall_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import *\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "a=[]\n",
    "a1=[]\n",
    "\n",
    "for img in glob.glob('dataset1/*/*'):\n",
    "    im = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(im,None)\n",
    "    a.append(kp);\n",
    "    #a1.append(principalComponents);\n",
    "    a1.append(des);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg1 = [[0] * 128] * len(a1)\n",
    "avg2=np.reshape(avg1,(-1,128))    \n",
    "for i in range(len(a1)):\n",
    "    for k in range (0,128):\n",
    "        s=0\n",
    "        for j in range(0,len(a1[i])):\n",
    "            s+=a1[i][j][k]\n",
    "            avg2[i][k]=(s/len(a1[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "for i in range(len(a1)):\n",
    "    for k in range (0,128):\n",
    "        pca = PCA(n_components=1)\n",
    "        principalComponents = pca.fit_transform(avg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "set=np.column_stack((pc,pc1,pc2,arr,pc3,pc4,pc5,pc6,principalComponents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4979919678714859\n",
      "Precision 0.47601700657966645\n",
      "recall 0.4623205721973919\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import glob\n",
    "p=[]\n",
    "r=[]\n",
    "label=[]\n",
    "for im in glob.glob('dataset1/*/*'):\n",
    "   l=(im.split('.')[0].split('\\\\')[1])\n",
    "   label.append(l)\n",
    "X_train, X_test, y_train, y_test = train_test_split(set, label, test_size=0.3,random_state=10)\n",
    "    \n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "p.append(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "r.append(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Precision\",precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"recall\",recall_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(829, 18)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4979919678714859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=3,\n",
    "                             random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4859437751004016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(n_neighbors=4)  \n",
    "classifier.fit(X_train, y_train)  \n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2971887550200803\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train) \n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4859437751004016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.feature import blob_dog\n",
    "from skimage import data, exposure\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "e=[]\n",
    "i=0\n",
    "for img in glob.glob('dataset1/*/*'):\n",
    "    e.append([])\n",
    "    image = imread(img)\n",
    "    image_gray = rgb2gray(image)\n",
    "    blobs_dog = blob_dog(image_gray, max_sigma=30, threshold=.1)\n",
    "    blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n",
    "    e[i].append(blobs_dog)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "m=0\n",
    "ar=[]\n",
    "\n",
    "l=range(len(e))\n",
    "for j in l:\n",
    "    k=[]\n",
    "    for i in e[j][0]:\n",
    "        k.append(i)\n",
    "    m=sum(k)/len(k)\n",
    "    m=m.flat\n",
    "    ar.append(list(m)) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os \n",
    "import glob \n",
    "opening = []\n",
    "feature =[]\n",
    "\n",
    "for im in glob.glob('dataset1/*/*'):\n",
    "   # im = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "   # im = cv2.UMat(img)\n",
    "    img = (cv2.imread(im, cv2.IMREAD_COLOR))\n",
    "    #imgUMat = cv2.UMat(img)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    feature = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    opening.append(feature)\n",
    "   \n",
    "myarray = np.asarray(opening)\n",
    "dataset_size = len(myarray)\n",
    "TwoDim_dataset = myarray.reshape(dataset_size,-2)\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pc7 = pca.fit_transform(TwoDim_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "set=np.column_stack((pc,pc1,pc2,arr,pc3,pc4,pc5,pc6,principalComponents,pc7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5180722891566265\n",
      "Precision 0.4907230898418698\n",
      "recall 0.4798729795370333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import glob\n",
    "p=[]\n",
    "r=[]\n",
    "label=[]\n",
    "for im in glob.glob('dataset1/*/*'):\n",
    "   l=(im.split('.')[0].split('\\\\')[1])\n",
    "   label.append(l)\n",
    "X_train, X_test, y_train, y_test = train_test_split(set, label, test_size=0.3,random_state=10)\n",
    "    \n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "p.append(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "r.append(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Precision\",precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"recall\",recall_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os \n",
    "import glob \n",
    "closing = []\n",
    "feature =[]\n",
    "\n",
    "for im in glob.glob('dataset1/*/*'):\n",
    "   # im = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "   # im = cv2.UMat(img)\n",
    "    img = (cv2.imread(im, cv2.IMREAD_COLOR))\n",
    "    #imgUMat = cv2.UMat(img)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    feature = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    closing.append(feature)\n",
    "   \n",
    "myarray = np.asarray(closing)\n",
    "dataset_size = len(myarray)\n",
    "TwoDim_dataset = myarray.reshape(dataset_size,-2)\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pc8 = pca.fit_transform(TwoDim_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "set=np.column_stack((pc,pc1,pc2,arr,pc3,pc4,pc5,pc6,principalComponents,pc7,pc8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5502008032128514\n",
      "Precision 0.5214860590072574\n",
      "recall 0.5181987825436873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import glob\n",
    "p=[]\n",
    "r=[]\n",
    "label=[]\n",
    "for im in glob.glob('dataset1/*/*'):\n",
    "   l=(im.split('.')[0].split('\\\\')[1])\n",
    "   label.append(l)\n",
    "X_train, X_test, y_train, y_test = train_test_split(set, label, test_size=0.3,random_state=10)\n",
    "    \n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "p.append(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "r.append(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Precision\",precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"recall\",recall_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os \n",
    "import glob \n",
    "from skimage.morphology import skeletonize,thin\n",
    "skeleton = []\n",
    "feature =[]\n",
    "\n",
    "\n",
    "for im in glob.glob('dataset1/*/*'):\n",
    "    image = cv2.imread(im,0)\n",
    "    image[image == 255] = 1\n",
    "    skeleton = thin(image)\n",
    "    skel=skeleton.astype(int)\n",
    "    #skel\n",
    "    feature.append(skel)\n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "myarray = np.asarray(feature)\n",
    "dataset_size = len(myarray)\n",
    "TwoDim_dataset = myarray.reshape(dataset_size,-1)\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pc9 = pca.fit_transform(TwoDim_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "set=np.column_stack((pc,pc1,pc2,arr,pc3,pc4,pc5,pc6,principalComponents,pc7,pc8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5502008032128514\n",
      "Precision 0.5214860590072574\n",
      "recall 0.5181987825436873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import glob\n",
    "p=[]\n",
    "r=[]\n",
    "label=[]\n",
    "for im in glob.glob('dataset1/*/*'):\n",
    "   l=(im.split('.')[0].split('\\\\')[1])\n",
    "   label.append(l)\n",
    "X_train, X_test, y_train, y_test = train_test_split(set, label, test_size=0.3,random_state=10)\n",
    "    \n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "p.append(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "r.append(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Precision\",precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"recall\",recall_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(829, 22)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('set.txt', set, fmt=\"%5.2f\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.66009527e+00, -2.21644681e+00,  4.73171558e-05, ...,\n",
       "         3.12628057e+03,  9.32741400e+02, -1.50807725e+03],\n",
       "       [-6.62969029e+00,  2.37912158e+00, -2.15445255e-06, ...,\n",
       "        -2.22845010e+03, -5.02694952e+02,  4.02286284e+02],\n",
       "       [-3.12755774e+00,  1.16736859e+00, -1.03213432e-05, ...,\n",
       "        -1.90777969e+03, -1.72918903e+03,  8.08859772e+02],\n",
       "       ...,\n",
       "       [ 3.95823212e+00,  2.25027160e+00,  2.41537458e-05, ...,\n",
       "         5.85957162e+02,  4.26204191e+03, -9.38002421e+02],\n",
       "       [-4.25118739e-01,  3.85463563e+00, -6.66614335e-06, ...,\n",
       "         4.06561878e+02,  2.27685432e+02, -6.61853424e+02],\n",
       "       [ 5.45601745e+00,  6.86953891e-01,  3.67338510e-05, ...,\n",
       "         3.39704203e+03,  4.37465743e+03, -3.81409822e+03]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(829, 22)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "set=pd.read_csv(\"s.csv\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5502008032128514\n",
      "Precision 0.5214860590072574\n",
      "recall 0.5181987825436873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import glob\n",
    "p=[]\n",
    "r=[]\n",
    "label=[]\n",
    "for im in glob.glob('dataset1/*/*'):\n",
    "   l=(im.split('.')[0].split('\\\\')[1])\n",
    "   label.append(l)\n",
    "X_train, X_test, y_train, y_test = train_test_split(set, label, test_size=0.3,random_state=10)\n",
    "    \n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "p.append(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "r.append(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Precision\",precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"recall\",recall_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
